{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_pytorch_basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysl208/pytorch_tutorial/blob/master/notebooks/01_pytorch_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Suop_td9b5I8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch Basics"
      ]
    },
    {
      "metadata": {
        "id": "pvpUb3Nxb5JK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Init, helpers, utils, ..."
      ]
    },
    {
      "metadata": {
        "id": "Tc1bZxKYb5JP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMe6XO2ocCBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNUh5Qeob5Jd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X2Jqri7Rb5Jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "d01fd85e-9bcd-4401-8c7c-180f7f85d528"
      },
      "cell_type": "code",
      "source": [
        "from ppt.utils import attr"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0bea746a14f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mppt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ppt'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3mhmG87Mb5Jy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "tensors - the atoms of machine learning"
      ]
    },
    {
      "metadata": {
        "id": "vs2rBlt2b5J1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensors in numpy and pytorch"
      ]
    },
    {
      "metadata": {
        "id": "RnrhO-qsb5J7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "from numpy.linalg import multi_dot as mdot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8UWd8drsb5KC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iq98ssIlb5KK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "38c37a72-97ec-4558-c75d-412eb2744a50"
      },
      "cell_type": "code",
      "source": [
        "# numpy\n",
        "np.eye(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "rhdulPD_b5KW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# torch\n",
        "torch.eye(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMEK_HI3b5Kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# numpy\n",
        "X = np.random.random((5, 3))\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HH75POzjb5Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pytorch\n",
        "Y = torch.rand((5, 3))\n",
        "Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQS6cC5Ab5K2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yodfLKiDb5K9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bkBW7r6b5LF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# numpy\n",
        "X.T @ X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jsfnT1RIb5LP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# torch\n",
        "Y.t() @ Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_1BWAnGb5LX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# numpy\n",
        "inv(X.T @ X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hlgu9wOEb5Lf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# torch\n",
        "torch.inverse(Y.t() @ Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzfP5VjTb5Ll",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## More on PyTorch Tensors"
      ]
    },
    {
      "metadata": {
        "id": "86c0EpdQb5Ls",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Operations are also available as methods."
      ]
    },
    {
      "metadata": {
        "id": "lRtjp4cgb5Ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A = torch.eye(3)\n",
        "A.add(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9Iq4uOLb5L8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZqDrLqYb5MF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x."
      ]
    },
    {
      "metadata": {
        "id": "L68D6AT8b5MK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A.add_(1)\n",
        "A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2HzO2xOb5MP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Indexing and broadcasting\n",
        "It works as expected:"
      ]
    },
    {
      "metadata": {
        "id": "YczaIPDfb5MU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A[0, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xptYJoxmb5Mm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uguf5pSdb5Mt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A[0:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3pFQhVspb5M5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A[:, 1:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OdKPOZPkb5M9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Converting"
      ]
    },
    {
      "metadata": {
        "id": "WyoXtfVgb5ND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A = torch.eye(3)\n",
        "A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAveUkA1b5NK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# torch --> numpy\n",
        "A.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ng0fQqYkb5NP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# numpy --> torch\n",
        "torch.from_numpy(np.eye(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvPyScPmb5NT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Autograd\n",
        "Prior to `v0.4` PyTorch used the class `Variable` to record gradients. You had to wrap `Tensor`s in `Variable`s.\n",
        "`Variable`s behaved like `Tensors`.\n",
        "\n",
        "With `v0.4` `Tensor` can record gradients directly if you tell it do do so, e.g. `torch.ones(3, requires_grad=True)`.\n",
        "There is no need for `Variable` anymore.\n",
        "\n",
        "Ref:\n",
        "- https://pytorch.org/docs/stable/autograd.html\n",
        "- https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
      ]
    },
    {
      "metadata": {
        "id": "3DpqINs0b5NW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import autograd  # you rarely use it directly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cmjou5qcb5Nd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = torch.ones(1)\n",
        "w.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUyguoEcb5Nh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = torch.ones(1) * 2\n",
        "z.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXPPkZMfb5No",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total = w + z\n",
        "total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJR13EOdb5Ns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What is going to happen here?\n",
        "total.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGFKM-XXb5Nv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cL4Ng729b5Nx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total = w + z\n",
        "total.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ry0gsNgcb5N4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ex_PBWBOb5OA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6p9orjlAb5OJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    total = w + z\n",
        "\n",
        "total.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TS9NbQnjb5OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# But what about the GPU?\n",
        "How do I use the GPU?\n",
        "\n",
        "If you have a GPU make sure that the right pytorch is installed\n",
        "\n",
        "```\n",
        "conda install pytorch torchvision cuda91 -c pytorch\n",
        "```\n",
        "Check https://pytorch.org/ for details."
      ]
    },
    {
      "metadata": {
        "id": "2TBxC0wHb5OQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "663149fe-57d0-4e3c-bbea-a7e38149b84c"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "5xLAY9-Xb5OT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you have a GPU you should get something like: \n",
        "`device(type='cuda', index=0)`\n",
        "\n",
        "You can move data to the GPU by doing `.to(device)`."
      ]
    },
    {
      "metadata": {
        "id": "AYvabJPvb5Oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "be2d8639-977f-487b-d75d-4cd5b1bd3641"
      },
      "cell_type": "code",
      "source": [
        "data = torch.eye(3)\n",
        "data.to(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "b34H5xppb5Oe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: before `v0.4` one had to use `.cuda()` and `.cpu()` to move stuff to and from the GPU.\n",
        "This littered the code with many:\n",
        "```python\n",
        "if CUDA:\n",
        "    model = model.cuda()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "GHVrzfYRb5Og",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LinReg with PyTorch, Gradient Descent, and GPU"
      ]
    },
    {
      "metadata": {
        "id": "YLckHSMNb5Oh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c39ffb97-37cc-46fa-9b2a-2733b76fa314"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "n_features = 1\n",
        "n_samples = 100\n",
        "\n",
        "X, y = make_regression(\n",
        "    n_samples=n_samples,\n",
        "    n_features=n_features,\n",
        "    noise=10,\n",
        ")\n",
        "\n",
        "fix, ax = plt.subplots()\n",
        "ax.plot(X, y, \".\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f401c3ccb00>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f401c3cca90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tdSWkgcBb5Om",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y.reshape((n_samples, n_features))).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mXHtsAob5O2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "class LinReg(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.beta = nn.Linear(input_dim, 1)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.beta(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCYYq2Rsb5O6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Move everything to GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LinReg(n_features).to(device)  # <-- here\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "X, y = X.to(device), y.to(device)  # <-- here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBl-xgP2b5O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train step\n",
        "model.train() # start train mode\n",
        "optimizer.zero_grad() # null's the gradient so that it doesn't accumulate\n",
        "\n",
        "y_ = model(X)\n",
        "loss = criterion(y_, y) # forward pass\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step() # updates params of the model\n",
        "\n",
        "# should split the data into train vs eval\n",
        "\n",
        "# Eval\n",
        "model.eval() # start eval mode\n",
        "with torch.no_grad():\n",
        "    y_ = model(X)    \n",
        "\n",
        "# Vis\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(X.cpu().numpy(), y_.cpu().numpy(), \".\", label=\"pred\")\n",
        "ax.plot(X.cpu().numpy(), y.cpu().numpy(), \".\", label=\"data\")\n",
        "ax.set_title(f\"MSE: {loss.item():0.1f}\")\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ciy7_tuPb5PC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Debugging\n",
        "\n",
        "**Q: \"No debugger for your code. What do you think?\"**\n",
        "\n",
        "**A: \"I would NOT be able to code!\"**\n",
        "\n",
        "- Who does \"print-line-debugging\"?\n",
        "- Who likes debugging in tensorflow?\n",
        "- What is the intersection of those two groups?\n",
        "\n",
        "\n",
        "## IPDB cheatsheet\n",
        "IPython Debugger\n",
        "\n",
        "Taken from http://frid.github.io/blog/2014/06/05/python-ipdb-cheatsheet/\n",
        "\n",
        "- h(help): Print help\n",
        "\n",
        "- n(ext): Continue execution until the next line in the current function is reached or it returns.\n",
        "- s(tep): Execute the current line, stop at the first possible occasion (either in a function that is called or in the current function).\n",
        "- r(eturn): Continue execution until the current function returns.\n",
        "\n",
        "- r(eturn): Continue execution until the current function returns.\n",
        "- a(rgs): Print the argument list of the current function."
      ]
    },
    {
      "metadata": {
        "id": "Oe3qQ9Lmb5PE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTegzsgKb5PG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "    answer = 42\n",
        "    set_trace()\n",
        "    answer += x\n",
        "    return answer\n",
        "\n",
        "my_function(12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ug98H8kab5PK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example: debuging a NN"
      ]
    },
    {
      "metadata": {
        "id": "YRs8d_0bb5PL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.rand((5, 3))\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mc2GFQODb5PM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(3, 1)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        # set_trace()\n",
        "        x = self.lin(X)\n",
        "        return X\n",
        "\n",
        "    \n",
        "model = MyModule()\n",
        "y_ = model(X)\n",
        "\n",
        "assert y_.shape == (5, 1), y_.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OnyXd3eVb5PW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recap - what we learned so far\n",
        "- Tensor like numpy\n",
        "- No need to calculate derivatives - automatic differentiation!\n",
        "- Use `nn.Module` to create your own networks\n",
        "- `set_trace` is your friend!"
      ]
    }
  ]
}